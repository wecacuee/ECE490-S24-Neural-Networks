{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d2da52-685e-4db6-beaf-a0c45fb0d1c5",
   "metadata": {},
   "source": [
    "# Micrtoroch Multi-layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b595cd3f-621f-4681-9e85-71fa20e5c5a9",
   "metadata": {},
   "source": [
    "## Create a Multi Layer Perceptron (MLP) to classify digits 0 and 1 from MNIST dataset\n",
    "(100 marks)\n",
    "\n",
    "Create a 2-layer Multi Layer Perceptron (MLP) to classify digits 0 and 1 from MNIST dataset.\n",
    "\n",
    "Use the same data and loss function as [Perceptron3.ipynb](https://colab.research.google.com/github/wecacuee/ECE490-S24-Neural-Networks/blob/master/notebooks/02-linear-models/Perceptron3.ipynb) but use MLP model instead of Linear model.\n",
    "\n",
    "You do not need to compute gradients by hand, you can use [AutogradNumpy.ipynb](https://colab.research.google.com/github/wecacuee/ECE490-S24-Neural-Networks/blob/master//notebooks/03-autograd/AutogradNumpy.ipynb). The notebook has been converted into a module, [microtorch.py](https://vikasdhiman.info/ECE490-S24-Neural-Networks/notebooks/05-mlp/microtorch.py) which can be imported. Another helper module will help you to keep track of all the parameters to update: [microtorch_nn.py](https://vikasdhiman.info/ECE490-S24-Neural-Networks/notebooks/05-mlp/microtorch_nn.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8a3533-fca9-48b5-81b8-da6a2c77c9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "### Code to the get the data\n",
    "! if [ ! -f zero_one_train_features.npz ]; then wget https://vikasdhiman.info/ECE490-S24-Neural-Networks/notebooks/05-mlp/zero_one_train_features.npz; fi\n",
    "def feature_n_pxls(imgs):\n",
    "    n, *shape = imgs.shape\n",
    "    return np.sum(imgs[:, :, :].reshape(n, -1) > 128, axis=1)\n",
    "\n",
    "def feature_y_var(imgs):\n",
    "    wts = imgs.mean(axis=-2)\n",
    "    mean = (np.arange(imgs.shape[-2]) * wts).sum(axis=-1) / wts.sum(axis=-1)\n",
    "    var = ((np.arange(imgs.shape[-2]) - mean[:, None])**2 * wts).sum(axis=-1) / wts.sum(axis=-1)\n",
    "    return var\n",
    "\n",
    "zero_one_train_features = np.load('zero_one_train_features.npz')\n",
    "FEATURE_MEAN = zero_one_train_features['mean']\n",
    "FEATURE_STD = zero_one_train_features['std']\n",
    "features = zero_one_train_features['normed_features']\n",
    "labels = zero_one_train_features['labels']\n",
    "\n",
    "\n",
    "def feature_extraction(imgs):\n",
    "    features = np.stack((feature_n_pxls(imgs),\n",
    "                     feature_y_var(imgs)), axis=-1)\n",
    "    return (features - FEATURE_MEAN) / FEATURE_STD\n",
    "\n",
    "def draw_features(ax, zero_features, one_features):\n",
    "    zf = ax.scatter(zero_features[:, 0], zero_features[:, 1], marker='.', label='0', alpha=0.5)\n",
    "    of = ax.scatter(one_features[:, 0], one_features[:, 1], marker='+', label='1', alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Feature 1: count of pixels')\n",
    "    ax.set_ylabel('Feature 2: Variance along x-axis')\n",
    "    return [zf, of] # return list of artists\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_features(ax, features[labels > 0, :], features[labels < 0, :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8f246e-1f25-4db2-a23d-537c9ed6b809",
   "metadata": {},
   "source": [
    "### Download manually or automatically\n",
    "\n",
    "Download micrtorch.py and micrtorch_nn.py to the current directory or let the code do it for you below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc51a58c-6187-4c0d-89e6-620bad0e4512",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dedf538411c68d1948d955f292e489a0",
     "grade": false,
     "grade_id": "cell-aed984948c9cd5f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def wget(url, filename):\n",
    "    \"\"\"\n",
    "    Download files using requests package\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import requests\n",
    "    except ImportError:\n",
    "        import subprocess\n",
    "        subprocess.call(\"pip install --user requests\".split())\n",
    "        import requests\n",
    "    r = requests.get(url)\n",
    "    with open(filename, 'wb') as fd:\n",
    "        for chunk in r.iter_content():\n",
    "            fd.write(chunk)\n",
    "    \n",
    "try:\n",
    "    import microtorch as t\n",
    "except ImportError:\n",
    "    wget('https://vikasdhiman.info/ECE490-S24-Neural-Networks/notebooks/05-mlp/microtorch.py',\n",
    "         'microtorch.py')\n",
    "    import microtorch as t\n",
    "    \n",
    "try:\n",
    "    import microtorch_nn as tnn\n",
    "except ImportError:\n",
    "    wget('https://vikasdhiman.info/ECE490-S24-Neural-Networks/notebooks/05-mlp/microtorch_nn.py',\n",
    "         'microtorch_nn.py')\n",
    "    import microtorch_nn as tnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1f543b-194c-4db1-8e63-878a41a311f4",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dedf538411c68d1948d955f292e489a0",
     "grade": false,
     "grade_id": "cell-aed984948c9cd5f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(predicted_labels, true_labels):\n",
    "    # Make sure predicted_labels and true_labels have same shape\n",
    "    ### BEGIN SOLUTION\n",
    "    y = true_labels[..., None]\n",
    "    yhat = predicted_labels\n",
    "    assert y.shape == yhat.shape\n",
    "    return t.maximum(- y * yhat, 0).sum()# / y.shape[-1]\n",
    "    ### END SOLUTION\n",
    "\n",
    "# TODO:\n",
    "# Define model = ?\n",
    "### BEGIN SOLUTION\n",
    "model = tnn.Sequential(\n",
    "    tnn.Linear(2, 5),\n",
    "    tnn.ReLU(),\n",
    "    tnn.Linear(5, 1))\n",
    "### END SOLUTION\n",
    "\n",
    "def train_by_gradient_descent(model, loss, train_features, train_labels, lr=0.0001):\n",
    "    train_features_tensor = t.Tensor(train_features)\n",
    "    predicted_labels = model(train_features_tensor)\n",
    "    #print(predicted_labels)\n",
    "    \n",
    "    loss_t = loss(predicted_labels, train_labels)\n",
    "    loss_t.backward(1)\n",
    "    loss_t_minus_1 = 2*loss_t.value  # Fake  value to make the while test pass once\n",
    "    niter = 0\n",
    "    while np.abs(loss_t.value - loss_t_minus_1) / loss_t.value > 0.01: # Stopping criterion\n",
    "        for param in model.parameters():\n",
    "            assert param.grad is not None\n",
    "            #print(\"before:\", id(param))\n",
    "            param.value = param.value - lr * param.grad  # Gradient descent\n",
    "            #print(\"after:\", id(param))\n",
    "        loss_t.zero_grad()\n",
    "        # Recompute the gradients\n",
    "        predicted_labels = model(train_features_tensor)\n",
    "        loss_t_minus_1 = loss_t.value\n",
    "        loss_t = loss(predicted_labels, train_labels)\n",
    "        loss_t.backward(1) # Compute gradients for next iteration\n",
    "        \n",
    "        # If loss increased, decrease lr. Works for gradient descent, not for stochatic gradient descent.\n",
    "        if loss_t.value > loss_t_minus_1:\n",
    "            lr = lr / 2\n",
    "        \n",
    "        ### DEBUGing information\n",
    "        iswrong = (train_labels * predicted_labels.value.ravel()) < 0\n",
    "        misclassified = (iswrong).sum() / iswrong.shape[0]\n",
    "        print(f\"loss: {loss_t.value:04.04f}, delta loss: {loss_t.value - loss_t_minus_1:04.04f},\" \n",
    "              f\"train misclassified: {misclassified:04.04f}\")\n",
    "        if niter % 20 == 0: # plot every 20th iteration\n",
    "            fig, ax = plt.subplots(1,1)\n",
    "            draw_features(ax, \n",
    "                          train_features[predicted_labels.value.ravel() > 0, :], \n",
    "                          train_features[predicted_labels.value.ravel() < 0, :])\n",
    "        \n",
    "        \n",
    "        niter += 1\n",
    "    return model\n",
    "\n",
    "trained_model = train_by_gradient_descent(model, loss, features, labels)\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1,2)\n",
    "draw_features(axes[0], features[labels > 0, :], features[labels < 0, :])\n",
    "axes[0].set_title('Train labels')\n",
    "predicted_labels = trained_model(features).value.flatten()\n",
    "draw_features(axes[1], features[predicted_labels > 0, :], features[predicted_labels < 0, :])\n",
    "axes[1].set_title('Predicted labels');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b54711-2731-486b-be71-b82c6f0fbe26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download MNIST dataset\n",
    "!F=t10k-images-idx3-ubyte && mkdir -p data && cd data && \\\n",
    "    [ ! -f $F ] && \\\n",
    "    wget http://yann.lecun.com/exdb/mnist/$F.gz  && \\\n",
    "    gunzip $F.gz\n",
    "!F=t10k-labels-idx1-ubyte && mkdir -p data && cd data && \\\n",
    "    [ ! -f $F ] && \\\n",
    "    wget http://yann.lecun.com/exdb/mnist/$F.gz  && \\\n",
    "    gunzip $F.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e2569e-4e82-4526-b6d6-7439a0b65d1e",
   "metadata": {
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4aa6df5f16e43b7135171b13637d2134",
     "grade": false,
     "grade_id": "cell-ac2aacd3f8d0c045",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset from uint8 byte files\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "# Ref:https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "def mnist_read_labels(fname='data/train-labels-idx1-ubyte'):\n",
    "    with open(fname, 'rb') as file:\n",
    "        # The file starts with 4 byte 2 unsigned ints \n",
    "        magic, size = struct.unpack('>II', file.read(8))\n",
    "        assert magic == 2049\n",
    "        labels = np.frombuffer(file.read(), dtype='u1')\n",
    "        return labels\n",
    "    \n",
    "# Ref:https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "def mnist_read_images(fname='data/train-images-idx3-ubyte'):\n",
    "    with open(fname, 'rb') as file:\n",
    "        # The file starts with 4 byte 4 unsigned ints \n",
    "        magic, size, rows, cols = struct.unpack('>IIII', file.read(16))\n",
    "        assert magic == 2051\n",
    "        image_data = np.frombuffer(file.read(), dtype='u1')\n",
    "        images = image_data.reshape(size, rows, cols)\n",
    "        return images\n",
    "test_images = mnist_read_images('data/t10k-images-idx3-ubyte')\n",
    "test_labels = mnist_read_labels('data/t10k-labels-idx1-ubyte')\n",
    "zero_one_filter = (test_labels == 0) | (test_labels == 1)\n",
    "zero_one_test_images = test_images[zero_one_filter, ...]\n",
    "zero_one_test_labels = test_labels[zero_one_filter, ...]\n",
    "\n",
    "\n",
    "def returnclasslabel(test_imgs):\n",
    "    Xtest = feature_extraction(test_imgs)\n",
    "    return np.where(\n",
    "        trained_model(Xtest).value.ravel() > 0, \n",
    "        0,\n",
    "        1)\n",
    "zero_one_predicted_labels = returnclasslabel(zero_one_test_images)\n",
    "\n",
    "# Find test_accuracy = ? \n",
    "### BEGIN SOLUTION\n",
    "test_accuracy = np.sum(zero_one_test_labels == zero_one_predicted_labels) / len(zero_one_test_labels)\n",
    "\n",
    "### END SOLUTION\n",
    "print(test_accuracy)\n",
    "assert test_accuracy > 0.90"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
