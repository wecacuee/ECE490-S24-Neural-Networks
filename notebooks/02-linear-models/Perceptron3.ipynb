{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44840b53",
   "metadata": {},
   "source": [
    "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
    "\n",
    "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f2ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"\"\n",
    "COLLABORATORS = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d0d5e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a100bb6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19250a1b-70ff-41e8-90ad-7dafc52554f6",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Perceptron_example.svg/500px-Perceptron_example.svg.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77743d7d-123a-41f0-87da-8fa04fe3d0a3",
   "metadata": {},
   "source": [
    "Latex macros\n",
    "$$\n",
    "\\newcommand{\\calA}{{\\cal A}}\n",
    "\\newcommand{\\calB}{{\\cal B}}\n",
    "\\newcommand{\\calC}{{\\cal C}}\n",
    "\\newcommand{\\calD}{{\\cal D}}\n",
    "\\newcommand{\\calE}{{\\cal E}}\n",
    "\\newcommand{\\calF}{{\\cal F}}\n",
    "\\newcommand{\\calG}{{\\cal G}}\n",
    "\\newcommand{\\calH}{{\\cal H}}\n",
    "\\newcommand{\\calI}{{\\cal I}}\n",
    "\\newcommand{\\calJ}{{\\cal J}}\n",
    "\\newcommand{\\calK}{{\\cal K}}\n",
    "\\newcommand{\\calL}{{\\cal L}}\n",
    "\\newcommand{\\calM}{{\\cal M}}\n",
    "\\newcommand{\\calN}{{\\cal N}}\n",
    "\\newcommand{\\calO}{{\\cal O}}\n",
    "\\newcommand{\\calP}{{\\cal P}}\n",
    "\\newcommand{\\calQ}{{\\cal Q}}\n",
    "\\newcommand{\\calR}{{\\cal R}}\n",
    "\\newcommand{\\calS}{{\\cal S}}\n",
    "\\newcommand{\\calT}{{\\cal T}}\n",
    "\\newcommand{\\calU}{{\\cal U}}\n",
    "\\newcommand{\\calV}{{\\cal V}}\n",
    "\\newcommand{\\calW}{{\\cal W}}\n",
    "\\newcommand{\\calX}{{\\cal X}}\n",
    "\\newcommand{\\calY}{{\\cal Y}}\n",
    "\\newcommand{\\calZ}{{\\cal Z}}\n",
    "\\newcommand{\\setA}{\\textsf{A}}\n",
    "\\newcommand{\\setB}{\\textsf{B}}\n",
    "\\newcommand{\\setC}{\\textsf{C}}\n",
    "\\newcommand{\\setD}{\\textsf{D}}\n",
    "\\newcommand{\\setE}{\\textsf{E}}\n",
    "\\newcommand{\\setF}{\\textsf{F}}\n",
    "\\newcommand{\\setG}{\\textsf{G}}\n",
    "\\newcommand{\\setH}{\\textsf{H}}\n",
    "\\newcommand{\\setI}{\\textsf{I}}\n",
    "\\newcommand{\\setJ}{\\textsf{J}}\n",
    "\\newcommand{\\setK}{\\textsf{K}}\n",
    "\\newcommand{\\setL}{\\textsf{L}}\n",
    "\\newcommand{\\setM}{\\textsf{M}}\n",
    "\\newcommand{\\setN}{\\textsf{N}}\n",
    "\\newcommand{\\setO}{\\textsf{O}}\n",
    "\\newcommand{\\setP}{\\textsf{P}}\n",
    "\\newcommand{\\setQ}{\\textsf{Q}}\n",
    "\\newcommand{\\setR}{\\textsf{R}}\n",
    "\\newcommand{\\setS}{\\textsf{S}}\n",
    "\\newcommand{\\setT}{\\textsf{T}}\n",
    "\\newcommand{\\setU}{\\textsf{U}}\n",
    "\\newcommand{\\setV}{\\textsf{V}}\n",
    "\\newcommand{\\setW}{\\textsf{W}}\n",
    "\\newcommand{\\setX}{\\textsf{X}}\n",
    "\\newcommand{\\setY}{\\textsf{Y}}\n",
    "\\newcommand{\\setZ}{\\textsf{Z}}\n",
    "\\newcommand{\\bfa}{\\mathbf{a}}\n",
    "\\newcommand{\\bfb}{\\mathbf{b}}\n",
    "\\newcommand{\\bfc}{\\mathbf{c}}\n",
    "\\newcommand{\\bfd}{\\mathbf{d}}\n",
    "\\newcommand{\\bfe}{\\mathbf{e}}\n",
    "\\newcommand{\\bff}{\\mathbf{f}}\n",
    "\\newcommand{\\bfg}{\\mathbf{g}}\n",
    "\\newcommand{\\bfh}{\\mathbf{h}}\n",
    "\\newcommand{\\bfi}{\\mathbf{i}}\n",
    "\\newcommand{\\bfj}{\\mathbf{j}}\n",
    "\\newcommand{\\bfk}{\\mathbf{k}}\n",
    "\\newcommand{\\bfl}{\\mathbf{l}}\n",
    "\\newcommand{\\bfm}{\\mathbf{m}}\n",
    "\\newcommand{\\bfn}{\\mathbf{n}}\n",
    "\\newcommand{\\bfo}{\\mathbf{o}}\n",
    "\\newcommand{\\bfp}{\\mathbf{p}}\n",
    "\\newcommand{\\bfq}{\\mathbf{q}}\n",
    "\\newcommand{\\bfr}{\\mathbf{r}}\n",
    "\\newcommand{\\bfs}{\\mathbf{s}}\n",
    "\\newcommand{\\bft}{\\mathbf{t}}\n",
    "\\newcommand{\\bfu}{\\mathbf{u}}\n",
    "\\newcommand{\\bfv}{\\mathbf{v}}\n",
    "\\newcommand{\\bfw}{\\mathbf{w}}\n",
    "\\newcommand{\\bfx}{\\mathbf{x}}\n",
    "\\newcommand{\\bfy}{\\mathbf{y}}\n",
    "\\newcommand{\\bfz}{\\mathbf{z}}\n",
    "\\newcommand{\\bfalpha}{\\boldsymbol{\\alpha}}\n",
    "\\newcommand{\\bfbeta}{\\boldsymbol{\\beta}}\n",
    "\\newcommand{\\bfgamma}{\\boldsymbol{\\gamma}}\n",
    "\\newcommand{\\bfdelta}{\\boldsymbol{\\delta}}\n",
    "\\newcommand{\\bfepsilon}{\\boldsymbol{\\epsilon}}\n",
    "\\newcommand{\\bfzeta}{\\boldsymbol{\\zeta}}\n",
    "\\newcommand{\\bfeta}{\\boldsymbol{\\eta}}\n",
    "\\newcommand{\\bftheta}{\\boldsymbol{\\theta}}\n",
    "\\newcommand{\\bfiota}{\\boldsymbol{\\iota}}\n",
    "\\newcommand{\\bfkappa}{\\boldsymbol{\\kappa}}\n",
    "\\newcommand{\\bflambda}{\\boldsymbol{\\lambda}}\n",
    "\\newcommand{\\bfmu}{\\boldsymbol{\\mu}}\n",
    "\\newcommand{\\bfnu}{\\boldsymbol{\\nu}}\n",
    "\\newcommand{\\bfomicron}{\\boldsymbol{\\omicron}}\n",
    "\\newcommand{\\bfpi}{\\boldsymbol{\\pi}}\n",
    "\\newcommand{\\bfrho}{\\boldsymbol{\\rho}}\n",
    "\\newcommand{\\bfsigma}{\\boldsymbol{\\sigma}}\n",
    "\\newcommand{\\bftau}{\\boldsymbol{\\tau}}\n",
    "\\newcommand{\\bfupsilon}{\\boldsymbol{\\upsilon}}\n",
    "\\newcommand{\\bfphi}{\\boldsymbol{\\phi}}\n",
    "\\newcommand{\\bfchi}{\\boldsymbol{\\chi}}\n",
    "\\newcommand{\\bfpsi}{\\boldsymbol{\\psi}}\n",
    "\\newcommand{\\bfomega}{\\boldsymbol{\\omega}}\n",
    "\\newcommand{\\bfxi}{\\boldsymbol{\\xi}}\n",
    "\\newcommand{\\bfell}{\\boldsymbol{\\ell}}\n",
    "\\newcommand{\\bfA}{\\mathbf{A}}\n",
    "\\newcommand{\\bfB}{\\mathbf{B}}\n",
    "\\newcommand{\\bfC}{\\mathbf{C}}\n",
    "\\newcommand{\\bfD}{\\mathbf{D}}\n",
    "\\newcommand{\\bfE}{\\mathbf{E}}\n",
    "\\newcommand{\\bfF}{\\mathbf{F}}\n",
    "\\newcommand{\\bfG}{\\mathbf{G}}\n",
    "\\newcommand{\\bfH}{\\mathbf{H}}\n",
    "\\newcommand{\\bfI}{\\mathbf{I}}\n",
    "\\newcommand{\\bfJ}{\\mathbf{J}}\n",
    "\\newcommand{\\bfK}{\\mathbf{K}}\n",
    "\\newcommand{\\bfL}{\\mathbf{L}}\n",
    "\\newcommand{\\bfM}{\\mathbf{M}}\n",
    "\\newcommand{\\bfN}{\\mathbf{N}}\n",
    "\\newcommand{\\bfO}{\\mathbf{O}}\n",
    "\\newcommand{\\bfP}{\\mathbf{P}}\n",
    "\\newcommand{\\bfQ}{\\mathbf{Q}}\n",
    "\\newcommand{\\bfR}{\\mathbf{R}}\n",
    "\\newcommand{\\bfS}{\\mathbf{S}}\n",
    "\\newcommand{\\bfT}{\\mathbf{T}}\n",
    "\\newcommand{\\bfU}{\\mathbf{U}}\n",
    "\\newcommand{\\bfV}{\\mathbf{V}}\n",
    "\\newcommand{\\bfW}{\\mathbf{W}}\n",
    "\\newcommand{\\bfX}{\\mathbf{X}}\n",
    "\\newcommand{\\bfY}{\\mathbf{Y}}\n",
    "\\newcommand{\\bfZ}{\\mathbf{Z}}\n",
    "\\newcommand{\\bfGamma}{\\boldsymbol{\\Gamma}}\n",
    "\\newcommand{\\bfDelta}{\\boldsymbol{\\Delta}}\n",
    "\\newcommand{\\bfTheta}{\\boldsymbol{\\Theta}}\n",
    "\\newcommand{\\bfLambda}{\\boldsymbol{\\Lambda}}\n",
    "\\newcommand{\\bfPi}{\\boldsymbol{\\Pi}}\n",
    "\\newcommand{\\bfSigma}{\\boldsymbol{\\Sigma}}\n",
    "\\newcommand{\\bfUpsilon}{\\boldsymbol{\\Upsilon}}\n",
    "\\newcommand{\\bfPhi}{\\boldsymbol{\\Phi}}\n",
    "\\newcommand{\\bfPsi}{\\boldsymbol{\\Psi}}\n",
    "\\newcommand{\\bfOmega}{\\boldsymbol{\\Omega}}\n",
    "\\newcommand{\\bbA}{\\mathbb{A}}\n",
    "\\newcommand{\\bbB}{\\mathbb{B}}\n",
    "\\newcommand{\\bbC}{\\mathbb{C}}\n",
    "\\newcommand{\\bbD}{\\mathbb{D}}\n",
    "\\newcommand{\\bbE}{\\mathbb{E}}\n",
    "\\newcommand{\\bbF}{\\mathbb{F}}\n",
    "\\newcommand{\\bbG}{\\mathbb{G}}\n",
    "\\newcommand{\\bbH}{\\mathbb{H}}\n",
    "\\newcommand{\\bbI}{\\mathbb{I}}\n",
    "\\newcommand{\\bbJ}{\\mathbb{J}}\n",
    "\\newcommand{\\bbK}{\\mathbb{K}}\n",
    "\\newcommand{\\bbL}{\\mathbb{L}}\n",
    "\\newcommand{\\bbM}{\\mathbb{M}}\n",
    "\\newcommand{\\bbN}{\\mathbb{N}}\n",
    "\\newcommand{\\bbO}{\\mathbb{O}}\n",
    "\\newcommand{\\bbP}{\\mathbb{P}}\n",
    "\\newcommand{\\bbQ}{\\mathbb{Q}}\n",
    "\\newcommand{\\bbR}{\\mathbb{R}}\n",
    "\\newcommand{\\bbS}{\\mathbb{S}}\n",
    "\\newcommand{\\bbT}{\\mathbb{T}}\n",
    "\\newcommand{\\bbU}{\\mathbb{U}}\n",
    "\\newcommand{\\bbV}{\\mathbb{V}}\n",
    "\\newcommand{\\bbW}{\\mathbb{W}}\n",
    "\\newcommand{\\bbX}{\\mathbb{X}}\n",
    "\\newcommand{\\bbY}{\\mathbb{Y}}\n",
    "\\newcommand{\\bbZ}{\\mathbb{Z}}\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b6a6f-c5da-43d4-8b08-531bd1247eb6",
   "metadata": {},
   "source": [
    "## Optimization for classification\n",
    "\n",
    "### Dataset\n",
    "Let the dataset $\\calD = \\{(\\bfx_1, y_1), \\dots, (\\bfx_n, y_n)\\}$, where $\\bfx_i \\in \\bbR^d$ is the feature vector and $y_i \\in \\{-1, +1\\}$ is the binary class label."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e74239e-4af6-4996-b661-e7618d25af8e",
   "metadata": {},
   "source": [
    "### Model\n",
    "We encode the prediction model as\n",
    "$$ \\hat{y}_i = f(\\bfx_i; \\bfm, c) = \\bfm^\\top \\bfx_i + c, $$\n",
    "where $\\bfm \\in \\bbR^{d}$ and $c \\in \\bbR$.\n",
    "\n",
    "We say that the prediction is of class $-1$, if $\\hat{y}_i < 0$ and $+1$ if $\\hat{y}_i > 0$.\n",
    "\n",
    "$\\DeclareMathOperator{\\sign}{sign}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782bac8-e268-442f-b97e-bbbb698a1f6f",
   "metadata": {},
   "source": [
    "### Loss function\n",
    "\n",
    "$$ l(y_i, \\hat{y}_i; \\bfm,c) = \\begin{cases}\n",
    "0 &\\text{ if } y_i \\hat{y}_i > 0 \\text{ or the sign of $y_i$ and $\\hat{y}_i$ is the same}\\\\\n",
    "|\\hat{y}_i| & \\text{ if } y_i \\hat{y}_i \\le 0 \\text{ or the sign of $y_i$ and $\\hat{y}_i$ is different}\n",
    "\\end{cases}$$\n",
    "\n",
    "\n",
    "$$ l(y_i, \\hat{y}_i; \\bfm,c) = \\begin{cases}\n",
    "0 &\\text{ if } y_i \\hat{y}_i > 0 \\\\\n",
    "-y_i \\hat{y}_i & \\text{ if } y_i \\hat{y}_i \\le 0\n",
    "\\end{cases}$$\n",
    "\n",
    "Let $$\\bfw = \\begin{bmatrix} \\bfm \\\\ c \\end{bmatrix} \\in \\bbR^{d+1}. $$\n",
    "\n",
    "Then $$\\hat{y}_i = f(\\bfx_i; \\bfm, c) = \\bfm^\\top \\bfx_i + c \n",
    "= \\begin{bmatrix} \\bfx_i^\\top & 1 \\end{bmatrix}\\begin{bmatrix} \\bfm \\\\ c \\end{bmatrix} \n",
    "= \\begin{bmatrix} \\bfx_i^\\top & 1 \\end{bmatrix} \\bfw$$\n",
    "\n",
    "We can rewrite loss interms of $\\bfw$,\n",
    "$$ l(y_i, \\hat{y}_i; \\bfw) = \\begin{cases}\n",
    "0 &\\text{ if } y_i \\hat{y}_i > 0 \\\\\n",
    "-y_i \\bfw^\\top \\begin{bmatrix}\\bfx_i \\\\ 1\\end{bmatrix} & \\text{ if } y_i \\hat{y}_i \\le 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40067fc-359a-44a5-b0e6-ce451ce12cf1",
   "metadata": {},
   "source": [
    "#### Optimization\n",
    "\n",
    "We want to find the parameters $\\bfw \\in \\bbR^{d+1}$ that minimize the loss over the entire dataset,\n",
    "$$ \\bfw^* = \\arg\\,\\min_{\\bfw} \\frac{1}{n} \\sum_{(\\bfx_i, y_i) \\in \\calD} l(y_i, \\hat{y}_i; \\bfw)$$\n",
    "\n",
    "To perform gradient descent on the loss function we need the gradient,\n",
    "$$ \\nabla_\\bfw \\frac{1}{n}\\sum_{(\\bfx_i, y_i) \\in \\calD} l(y_i, \\hat{y}_i; \\bfw) = \\frac{1}{n}\\sum_{(\\bfx_i, y_i) \\in \\calD} \\nabla_\\bfw  l(y_i, \\hat{y}_i; \\bfw) = \\frac{1}{n}\\sum_{(\\bfx_i, y_i) \\in \\calD}\\begin{cases}\n",
    "0 &\\text{ if } y_i \\hat{y}_i > 0 \\\\\n",
    " -y_i \\begin{bmatrix}\\bfx_i \\\\ 1\\end{bmatrix} & \\text{ if } y_i \\hat{y}_i \\le 0\n",
    "\\end{cases}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61eb0701-f287-425c-8172-de3f47a29fea",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download MNIST dataset\n",
    "!mkdir -p data\n",
    "!F=train-images-idx3-ubyte && cd data && \\\n",
    "    [ ! -f $F ] && \\\n",
    "    wget http://yann.lecun.com/exdb/mnist/$F.gz  && \\\n",
    "    gunzip $F.gz\n",
    "!F=train-labels-idx1-ubyte && cd data && \\\n",
    "    [ ! -f $F ] && \\\n",
    "    wget http://yann.lecun.com/exdb/mnist/$F.gz  && \\\n",
    "    gunzip $F.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dfdea-79af-4abd-ae9c-55c2c3c01cd2",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load MNIST dataset from uint8 byte files\n",
    "import struct\n",
    "import numpy as np\n",
    "\n",
    "# Ref:https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "def mnist_read_labels(fname='data/train-labels-idx1-ubyte'):\n",
    "    with open(fname, 'rb') as file:\n",
    "        # The file starts with 4 byte 2 unsigned ints \n",
    "        magic, size = struct.unpack('>II', file.read(8))\n",
    "        assert magic == 2049\n",
    "        labels = np.frombuffer(file.read(), dtype='u1')\n",
    "        return labels\n",
    "    \n",
    "# Ref:https://github.com/sorki/python-mnist/blob/master/mnist/loader.py\n",
    "def mnist_read_images(fname='data/train-images-idx3-ubyte'):\n",
    "    with open(fname, 'rb') as file:\n",
    "        # The file starts with 4 byte 4 unsigned ints \n",
    "        magic, size, rows, cols = struct.unpack('>IIII', file.read(16))\n",
    "        assert magic == 2051\n",
    "        image_data = np.frombuffer(file.read(), dtype='u1')\n",
    "        images = image_data.reshape(size, rows, cols)\n",
    "        return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17492446",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Visualize the dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "mpl.rc('animation', html='jshtml')\n",
    "train_images = mnist_read_images('data/train-images-idx3-ubyte')\n",
    "labels = mnist_read_labels('data/train-labels-idx1-ubyte')\n",
    "zero_images = train_images[labels==0, ...] # Filter by label == 0\n",
    "one_images = train_images[labels==1, ...] # Filter by label == 1\n",
    "        \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "# ims is a list of lists, each row is a list of artists to draw in the\n",
    "# current frame; here we are just animating one artist, the image, in\n",
    "# each frame\n",
    "ims = [[ax.imshow(np.hstack((zero_images[i], one_images[i])), animated=True, cmap='gray', vmin=0, vmax=255)]\n",
    "    for i in range(60)]\n",
    "zero_images_anim = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n",
    "                                repeat_delay=1000, repeat=False)\n",
    "zero_images_anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6115564",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Images as arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d005a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506bda4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "img1 = train_images[0]\n",
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50580dcb",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "## Visualizing matrices\n",
    "fig, ax = plt.subplots()\n",
    "ax.axis('off')\n",
    "ax.imshow([[1, 0],\n",
    "           [0, 1]], cmap='gray')\n",
    "# ax.imshow(np.random.rand(28, 28), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ace721-4b00-4180-a6c9-9f779098a9d9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "zero_images_anim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9574e534-6242-4c08-9347-e5c1fcfe0cb5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# What is a feature\n",
    "\n",
    "Any property of data sample that helps with the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de75c7a8-3a7f-4934-b7c6-d86775db964d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def feature_n_pxls(imgs):\n",
    "    n, *shape = imgs.shape\n",
    "    return np.sum(imgs[:, :, :].reshape(n, -1) > 128, axis=1)\n",
    "\n",
    "n_pxls_zero_images = feature_n_pxls(zero_images)\n",
    "n_pxls_one_images = feature_n_pxls(one_images)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(n_pxls_zero_images, '.')\n",
    "ax.plot(n_pxls_one_images, '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d1359d-7774-4aad-9bed-545bd398f365",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "for i in range(5):\n",
    "    ax.plot(zero_images[i].mean(axis=0), 'b-', label='0')\n",
    "for i in range(5):\n",
    "    ax.plot(one_images[i].mean(axis=0), 'r-', label='1')\n",
    "ax.legend()\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('Averge intensity')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ce9ad8",
   "metadata": {},
   "source": [
    "We will compute the intensity weighted variance of image along the image rows so that we can take the variance along the rows as a measure fo the spread along the $x$ axis.\n",
    "\n",
    "Let the `img` be denoted as an array $I \\in \\bbR^{H \\times W}$ where $H$ is the height and $W$ is the width of the array.\n",
    "\n",
    "Let's first compute the average intensity along the columns and call that `wts` in the python program and $\\bfw$ in maths,\n",
    "\n",
    "$$ w(c) = \\frac{1}{H} \\sum_{r =1}^H I(r, c) $$\n",
    "$$ \\bfw = \\begin{bmatrix} w(c=1) & w(c=2) & \\dots & w(c=W)  \\end{bmatrix} \\in \\bbR^{1 \\times W}$$\n",
    "\n",
    "For the first image in `zero_images`, computing the `wts` vector is one line of code in numpy,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02420db-ae08-4a15-8fa1-8201063e6f38",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wts = zero_images[0].mean(axis=0)\n",
    "wts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332eedc3-a88d-4ac1-9128-ff3c0a1e47b0",
   "metadata": {},
   "source": [
    "Now we want to compute the mean and variance of the column variable $c$ weighted by the weight vector $\\bfw$\n",
    "$$ \\mu_c(\\bfw) =  \\frac{\\sum_{c = 1}^{W} c w(c)}{\\sum_{c=1}^{W} w(c)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0157d-c08b-4a60-a8c3-7e3f2cbe4dab",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "cs = np.arange(wts.shape[0]) # cs = [1, ..., W]\n",
    "mean = (cs * wts).sum() / wts.sum()\n",
    "mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8441093c-1ac7-4fb5-91d2-cda01b5285f7",
   "metadata": {},
   "source": [
    "Now we do the same with variance,\n",
    "$$ \\sigma^2_c(\\bfw) = \\sum_{c=1}^W \\frac{(c - \\mu_c)^2 w(c)}{\\sum_{x=1}^{W} w(c)}  $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3decad2-a5c7-47d1-9e52-8e2586e28b2f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "var = ((cs - mean)**2 * wts).sum() / wts.sum()\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6026de17-d2b6-4527-8007-f508a35fec22",
   "metadata": {},
   "source": [
    "Put it all together in a function so that we can repeatedly run in on all the images,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd57644-513b-4639-affd-25eeaad11d83",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def feature_y_var(img):\n",
    "    wts = img.mean(axis=0)\n",
    "    mean = (np.arange(wts.shape[0]) * wts).sum() / np.sum(wts)\n",
    "    var = ((np.arange(wts.shape[0]) - mean)**2 * wts).sum() / np.sum(wts)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661eb94-0987-411a-9f5d-d7da2eff175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_y_var(zero_images[0]), feature_y_var(one_images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c88944-20ec-41f6-b5f9-171a45e04f62",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def feature_y_var(imgs):\n",
    "    wts = imgs.mean(axis=-2)\n",
    "    arange = np.arange(wts.shape[-1])\n",
    "    mean = (arange * wts).sum(axis=-1) / wts.sum(axis=-1)\n",
    "    mean = mean[:, np.newaxis]\n",
    "    var = ((arange - mean)**2 * wts).sum(axis=-1) / wts.sum(axis=-1)\n",
    "    return var\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(feature_y_var(zero_images), '.')\n",
    "ax.plot(feature_y_var(one_images), '+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f93f75c",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def features_extract(images):\n",
    "    return np.vstack((feature_n_pxls(images),\n",
    "                      feature_y_var(images))).T\n",
    "zero_features = features_extract(zero_images)\n",
    "one_features = features_extract(one_images)\n",
    "\n",
    "\n",
    "def draw_features(ax, zero_features, one_features):\n",
    "    zf = ax.scatter(zero_features[:, 0], zero_features[:, 1], marker='.', label='0', alpha=0.5)\n",
    "    of = ax.scatter(one_features[:, 0], one_features[:, 1], marker='+', label='1', alpha=0.3)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel('Feature 1: count of pixels')\n",
    "    ax.set_ylabel('Feature 2: Variance along x-axis')\n",
    "    return [zf, of] # return list of artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c911ae0a-9875-42bf-949d-ebf35fc99ecf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "draw_features(ax, zero_features, one_features)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9edc78-9dc0-4208-98bd-e46c4f2d81e6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bfw = np.ones(3)\n",
    "fig, ax = plt.subplots()\n",
    "draw_features(ax, zero_features, one_features)\n",
    "x = np.linspace(-1, 1, 21)\n",
    "ax.plot(x, (x*bfw[0] + bfw[2])/bfw[1], 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e57213f-6414-43cf-a4e9-82b544ed82aa",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "bfw = np.ones(3)\n",
    "\n",
    "Y = np.hstack((np.ones(zero_features.shape[0]), np.full(one_features.shape[0], -1.0)))\n",
    "features = np.vstack((zero_features, one_features))\n",
    "FEATURES_MEAN = features.mean(axis=0, keepdims=1)\n",
    "FEATURES_STD = features.std(axis=0, keepdims=1)\n",
    "\n",
    "def norm_features(features):\n",
    "    return (features - FEATURES_MEAN) / FEATURES_STD\n",
    "    \n",
    "X = norm_features(features)\n",
    "\n",
    "np.savez('zero_one_train_features.npz', \n",
    "         mean=FEATURES_MEAN, std=FEATURES_STD,\n",
    "         normed_features=X,\n",
    "         labels=Y)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "draw_features(ax, X[Y > 0, :], X[Y < 0, :])\n",
    "x = np.linspace(-1, 1, 21)\n",
    "ax.plot(x, -(x*bfw[0] + bfw[2])/bfw[1], 'r-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9b45a8-33f8-4a81-8983-01cc94355579",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd9c81d-181a-4309-b451-a0ae1b25182e",
   "metadata": {},
   "source": [
    "Concatenate 1 to all $X$\n",
    "$$\\bar{X} = \\begin{bmatrix}\n",
    "X_{n \\times 2},& \\mathbf{1}_{n \\times 1}\n",
    "\\end{bmatrix} \\in \\bbR^{n \\times 3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14e979c-6e69-4bb9-ba0c-a54f96961b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_and_1 = np.hstack((X, np.ones((X.shape[0], 1))))\n",
    "X_and_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742d2818-f18c-4bc2-ae94-6e5d018c0806",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Homework 4: Problem 4 (10 marks)\n",
    "\n",
    "Implement a function `model` that takes the dataset inputs $\\bar{X} \\in \\bbR^{n \\times 3}$, the dataset labels, and the weight vector $\\bfw \\in \\bbR^3$ and returns the $\\hat{y}_i$ for all elements in the dataset,\n",
    "$$ \\hat{y}_i = f(\\bfx_i; \\bfw) = \\bfw^\\top \\begin{bmatrix}\\bfx_i \\\\ 1\\end{bmatrix} $$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b5cd3b-51ca-43e8-bd50-a563360f505d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fa3f9d7632ea11f30620a48db2a22975",
     "grade": false,
     "grade_id": "cell-8f18079f90bd4caa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model(X_and_1, bfw):\n",
    "    \"\"\"\n",
    "    X_and_1.shape = (n, 3)\n",
    "    bfw.shape = (3,)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return Yhat # Yhat.shape = (n,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2791119-834e-4cf1-b2dc-9fa0d091bba4",
   "metadata": {},
   "source": [
    "You are given the implementation of the function `loss` that takes the dataset inputs $\\bar{X} \\in \\bbR^{n \\times 3}$, the dataset labels, $Y \\in \\{0, 1\\}^{n}$ and the weight vector $\\bfw \\in \\bbR^3$ and returns the total loss for all elements in the dataset,\n",
    "\n",
    "\n",
    "\n",
    "$$ \\frac{1}{n} \\sum_{(x_i, y_i) \\in \\calD} l(y_i, \\hat{y}_i; \\bfw) = \\frac{1}{n} \\sum_{(x_i, y_i) \\in \\calD}  \\begin{cases}\n",
    "0 &\\text{ if } y_i \\hat{y}_i > 0 \\\\\n",
    "-y_i \\bfw^\\top \\begin{bmatrix}\\bfx_i \\\\ 1\\end{bmatrix} & \\text{ if } y_i \\hat{y}_i \\le 0\n",
    "\\end{cases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63561038-7141-4e53-bf0d-80ca877ba29e",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss(X_and_1, Y, bfw):\n",
    "    \"\"\"\n",
    "    X_and_1.shape = (n, 3)\n",
    "    Y.shape = (n,)\n",
    "    bfw.shape = (3,)\n",
    "    \"\"\"\n",
    "    Yhat = model(X_and_1, bfw)\n",
    "    YYhat = Y * Yhat  # YYhat.shape = (n,) \n",
    "    l_per_sample = np.where(YYhat > 0, 0, -YYhat) # l_per_sample.shape = (n,) \n",
    "    l_mean = l_per_sample.mean(axis=-1) # l_per_sample.shape = (n,) \n",
    "    return l_mean # l_mean.shape = (1,) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483e2c0c-cc44-4aa6-bf81-bb3b61cc55b6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Homework 4: Problem 5 (10 marks)\n",
    "\n",
    "Implement a function `grad_loss` that takes the dataset inputs `X_and_1` $\\bar{X} \\in \\bbR^{n \\times 3}$, the dataset labels, $Y \\in \\{0, 1\\}^{n}$ and the weight vector $\\bfw \\in \\bbR^3$ and returns the total loss for all elements in the dataset,\n",
    "\n",
    "\n",
    "\n",
    "$$ \\nabla_\\bfw \\left( \\frac{1}{n} \\sum_{(\\bfx_i, y_i) \\in \\calD}  l(y_i, \\hat{y}_i; \\bfw) \\right) =  \\frac{1}{n} \\sum_{(\\bfx_i, y_i) \\in \\calD} \\begin{cases}\n",
    "0 &\\text{ if } y_i \\hat{y}_i > 0 \\\\\n",
    " -y_i \\begin{bmatrix}\\bfx_i \\\\ 1\\end{bmatrix} & \\text{ if } y_i \\hat{y}_i \\le 0\n",
    "\\end{cases}$$\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dc8b1e-1471-4195-b3a6-404241927ec1",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "73bb3f2e434e766c14a94332e3c00c56",
     "grade": false,
     "grade_id": "cell-caab8192cf4a6af9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grad_loss(X_and_1, Y, bfw):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    return grad_L_total # grad_L_total.shape = (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9568d7e-767b-48ee-b343-5a234da5f000",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lr_scheduler(t, lr0=1, lr_end=0.001, t0=0, t_end=500, curv=4):\n",
    "    normalized = (np.exp(-curv*(t-t0)/(t_end-t0))-1) / (np.exp(-curv) - 1)\n",
    "    return (lr_end - lr0) * normalized + lr0\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(lr_scheduler(np.arange(500)))\n",
    "lr_scheduler(500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1f3f2b-760c-46d9-990c-f956b65d5f9b",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Homework 4: Problem 6 (10 marks)\n",
    "\n",
    "Implement gradient descent to find $\\bfw$ that minimizes $\\nabla_\\bfw \\frac{1}{n} \\sum_{(\\bfx_i, y_i) \\in \\calD}  l(y_i, \\hat{y}_i; \\bfw)$\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f43228-1116-46ef-a7e6-85495eb8888b",
   "metadata": {},
   "source": [
    "Algorithm 9.3 Gradient descent method.\n",
    "\n",
    "**given** a starting point $\\bfx \\in \\text{dom}{f}$ .\n",
    "\n",
    "**repeat**\n",
    "1. Choose step size $\\alpha_t$ \n",
    "2. Update. $\\bfx := \\bfx  - \\alpha_t \\nabla f(\\bfx) $\n",
    "\n",
    "**until** stopping criterion is satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e922c813-0c2a-48e1-8b34-6fb2b6f2d80d",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b58509a8fd0fd0502c549ad06811db28",
     "grade": false,
     "grade_id": "cell-b03dc89dc481b312",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "-"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(X_and_1, Y, lr_scheduler = lr_scheduler, MAX_ITER=500, SMALLEST_GRAD_L_NORM=0.001):\n",
    "    \"\"\"\n",
    "    X_and_1.shape is (n, 3)\n",
    "    Y.shape is (n, )\n",
    "\n",
    "    Write a function that returns\n",
    "\n",
    "    bfw : the solution for bfw that you get after gradient descent\n",
    "    list_of_bfws : the list of bfw at each iteration of gradient descent\n",
    "    list_of_losses : the list of loss() values that you get at each iteration of gradient descent\n",
    "    \"\"\"\n",
    "    bfw = np.random.rand(3)*4-2\n",
    "    list_of_bfws = [bfw]\n",
    "    list_of_losses = []\n",
    "    \n",
    "    grad_l = grad_loss(X_and_1, Y, bfw)\n",
    "    list_of_losses.append(loss(X_and_1, Y, bfw))\n",
    "    for t in range(MAX_ITER):\n",
    "        if np.linalg.norm(grad_l) < SMALLEST_GRAD_L_NORM:\n",
    "            break\n",
    "        learning_rate = lr_scheduler(t)\n",
    "        \n",
    "        # 1. Compute grad_loss for current bfw\n",
    "        # 2. Update bfw using gradient descent\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        list_of_bfws.append(bfw)\n",
    "        list_of_losses.append(loss(X_and_1, Y, bfw))\n",
    "    return bfw, list_of_bfws, list_of_losses\n",
    "\n",
    "OPTIMAL_BFW, list_of_bfws, list_of_losses = train(X_and_1, Y)\n",
    "OPTIMAL_BFW /= np.linalg.norm(OPTIMAL_BFW)\n",
    "print(\"optimal loss\", list_of_losses[-2:])\n",
    "print(\"optimal bfw\", OPTIMAL_BFW)\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(list_of_losses)\n",
    "ax.set_xlabel('t')\n",
    "ax.set_ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fbfdd-364b-4a47-93b7-e2fdbedaac5f",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def project_bfw_to_mc(bfw):\n",
    "    \"\"\"\n",
    "    bfw = [w1, w2, w3]\n",
    "    \n",
    "    Converts equation of line \n",
    "        w1 x + w2 y + w3 = 0\n",
    "    to \n",
    "        - m x + y - c = 0\n",
    "\n",
    "    return [m, c]\n",
    "    \"\"\"\n",
    "    bfw_normalized = bfw / np.linalg.norm(bfw)\n",
    "    assert np.abs(bfw_normalized[..., 1]) > 1e-4 \n",
    "    m = -bfw_normalized[0] / bfw_normalized[1]\n",
    "    c = -bfw_normalized[2] / bfw_normalized[1]\n",
    "    return m, c\n",
    "\n",
    "def lift_mc_to_bfw(m, c):\n",
    "    \"\"\"\n",
    "    Converts equation of line \n",
    "        - m x + y - c = 0\n",
    "    to \n",
    "        w1 x + w2 y + w3 = 0\n",
    "\n",
    "    returns bfw = [w1, w2, w3]\n",
    "    \"\"\"\n",
    "    bfw_norm_sq = 1 +  m**2 + c**2\n",
    "    bfw_norm = np.sqrt(bfw_norm_sq)\n",
    "    w1 = - m / bfw_norm\n",
    "    w2 = np.sqrt(1 - (m**2 + c**2)/bfw_norm_sq)\n",
    "    w3 = - c / bfw_norm\n",
    "    return np.concatenate((w1[..., None], w2[..., None], w3[..., None]),\n",
    "                          axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3ee67e-6942-4559-9050-26cf78ef3938",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(5, 7.5))\n",
    "class Anim:\n",
    "    def __init__(self, fig, axes, X_and_1, Y):\n",
    "        self.fig = fig\n",
    "        self.ax = axes[0]\n",
    "        self.ax1 = axes[1]\n",
    "        self.fts = draw_features(self.ax, X_and_1[Y > 0, :2], X_and_1[Y < 0, :2])\n",
    "        self.line, = self.ax.plot([], [], 'r-')\n",
    "        \n",
    "        m, c = np.meshgrid(np.linspace(-10, 0, 51), np.linspace(-1, 1, 51))\n",
    "        bfw = lift_mc_to_bfw(m, c)\n",
    "        totalloss = np.empty_like(m)\n",
    "        for i in range(m.shape[0]):\n",
    "            for j in range(m.shape[1]):\n",
    "                totalloss[i, j] = loss(X_and_1, Y, bfw[i, j, :])\n",
    "\n",
    "        self.ctr = self.ax1.contour(m, c, totalloss, 30, cmap='Blues_r')\n",
    "        self.ax1.set_xlabel('m')\n",
    "        self.ax1.set_ylabel('c')\n",
    "        self.ax1.clabel(self.ctr, self.ctr.levels, inline=True, fontsize=6)\n",
    "        self.m_hist = []\n",
    "        self.c_hist = []\n",
    "        self.line2, = self.ax1.plot([], [], 'r*-')\n",
    "\n",
    "        \n",
    "    def anim_init(self):\n",
    "        return (self.line, self.line2)\n",
    "        \n",
    "    def update(self, bfw):\n",
    "        x = np.linspace(-2, 2, 21)\n",
    "        m, c = project_bfw_to_mc(bfw)\n",
    "        self.line.set_data(x, x * m + c)\n",
    "        self.m_hist.append(m)\n",
    "        self.c_hist.append(c)\n",
    "        self.line2.set_data(self.m_hist, self.c_hist)\n",
    "        return self.line, self.line2\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(5, 7.5))    \n",
    "a = Anim(fig, axes, X_and_1, Y)\n",
    "animation.FuncAnimation(fig, a.update, frames=list_of_bfws[::5],\n",
    "                        init_func=a.anim_init, blit=True, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fe7fb4-f20d-461d-b1a7-85f2e5ff24b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download MNIST dataset\n",
    "!mkdir -p data\n",
    "!F=t10k-images-idx3-ubyte && cd data && \\\n",
    "    [ ! -f $F ] && \\\n",
    "    wget http://yann.lecun.com/exdb/mnist/$F.gz  && \\\n",
    "    gunzip $F.gz\n",
    "!F=t10k-labels-idx1-ubyte && cd data && \\\n",
    "    [ ! -f $F ] && \\\n",
    "    wget http://yann.lecun.com/exdb/mnist/$F.gz  && \\\n",
    "    gunzip $F.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffff3373",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "test_images = mnist_read_images('data/t10k-images-idx3-ubyte')\n",
    "test_labels = mnist_read_labels('data/t10k-labels-idx1-ubyte')\n",
    "zero_one_filter = (test_labels == 0) | (test_labels == 1)\n",
    "zero_one_test_images = test_images[zero_one_filter, ...]\n",
    "zero_one_test_labels = test_labels[zero_one_filter, ...]\n",
    "\n",
    "\n",
    "np.savez('zero_one_PERCEPTRON_optmial_bfw.npz', \n",
    "         optimal_bfw=OPTIMAL_BFW)\n",
    "\n",
    "def returnclasslabel(test_imgs):\n",
    "    Xtest = norm_features(features_extract(test_imgs))\n",
    "    Xtest_and_1 = np.hstack((Xtest, np.ones((*Xtest.shape[:-1], 1))))\n",
    "    bfw = OPTIMAL_BFW\n",
    "    return np.where(\n",
    "        model(Xtest_and_1, bfw) > 0, \n",
    "        0,\n",
    "        1)\n",
    "zero_one_predicted_labels = returnclasslabel(zero_one_test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab42be01-5330-45dd-b202-3168d368c4d6",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = np.sum(zero_one_test_labels == zero_one_predicted_labels) / len(zero_one_test_labels)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3d53d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_label = 1\n",
    "negative_label = 0\n",
    "TP = np.sum((zero_one_test_labels == positive_label) & (zero_one_predicted_labels == positive_label))\n",
    "TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08d048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN =  np.sum((zero_one_test_labels == negative_label) & (zero_one_predicted_labels == negative_label))\n",
    "TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b08072",
   "metadata": {},
   "outputs": [],
   "source": [
    "FP = np.sum((zero_one_test_labels != positive_label) & (zero_one_predicted_labels == positive_label))\n",
    "FP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140b8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "FN = np.sum((zero_one_test_labels != negative_label) & (zero_one_predicted_labels == negative_label))\n",
    "FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec4b38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "fig, ax = plt.subplots()\n",
    "ax.imshow([[TN, FN],\n",
    "          [FP, TP]])\n",
    "ax.set_xlabel('predicted')\n",
    "ax.set_ylabel('true')\n",
    "ax.set_xticks([0, 1])\n",
    "ax.set_yticks([0, 1])\n",
    "ax.text(0, 0, 'TN = %.3f' % TN)\n",
    "ax.text(1, 0, 'FN = %.3f' % FN, color='w')\n",
    "ax.text(0, 1, 'FP = %.3f' % FP, color='w')\n",
    "ax.text(1, 1, 'TP = %.3f' % TP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b70cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "PRECISION = TP / (TP + FP)\n",
    "PRECISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8b52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "RECALL = TP / (TP + FN)\n",
    "RECALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47130bbc-64c7-4423-8037-a6d672822103",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots()\n",
    "artists = []\n",
    "for i in range(60):\n",
    "    artists.append(\n",
    "        [ax.imshow(zero_one_test_images[i], animated=True, cmap='gray', vmin=0, vmax=255),\n",
    "        ax.text(0, 2, 'The number is %d' % zero_one_predicted_labels[i], animated=True, color='w')])\n",
    "animation.ArtistAnimation(fig, artists, interval=50, blit=True,\n",
    "                                repeat_delay=1000, repeat=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
